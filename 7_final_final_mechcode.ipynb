{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape[0] = 42\n",
      "X_train.shape[1] = 6\n",
      "y_train.shape[0] = 42\n",
      "y_train.shape[1] = 1\n"
     ]
    }
   ],
   "source": [
    "#import pandas and numpy library for datamanupulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing training set or X_train\n",
    "training_set = pd.read_csv('C:/Users/sivge/Desktop/Major Project/Main data 80,20/Xtrain 80,20.csv', header=None, names=['Watts', 'Inclination', 'Flow Rate', 'Fluid_ratio','T Atmosphere','Water_Inlet_Temperature'])\n",
    "X_train = training_set.iloc[:, :].values #load values in X_train)\n",
    "X_train = training_set.iloc[:, :].values #load values in X_train\n",
    "\n",
    "#Importing Y_train \n",
    "y = pd.read_csv('C:/Users/sivge/Desktop/Major Project/Main data 80,20/Ytrain 80,20.csv', header=None, names=['Outlet'])\n",
    "y_train= y.iloc[ :, :1].values\n",
    "#print X_train.Shape[0] and X_train.Shape[1]\n",
    "print(\"X_train.shape[0] = \" + str(X_train.shape[0]))\n",
    "print(\"X_train.shape[1] = \" + str(X_train.shape[1]))\n",
    "print(\"y_train.shape[0] = \" + str(y_train.shape[0]))\n",
    "print(\"y_train.shape[1] = \" + str(y_train.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Watts</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>Flow Rate</th>\n",
       "      <th>Fluid_ratio</th>\n",
       "      <th>T Atmosphere</th>\n",
       "      <th>Water_Inlet_Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.026381</td>\n",
       "      <td>31.478524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.680929</td>\n",
       "      <td>32.132071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.770452</td>\n",
       "      <td>32.219429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.741786</td>\n",
       "      <td>32.091071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.711814</td>\n",
       "      <td>32.073558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.699886</td>\n",
       "      <td>32.050455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.651714</td>\n",
       "      <td>31.968500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.909881</td>\n",
       "      <td>31.684571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.924000</td>\n",
       "      <td>32.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.027071</td>\n",
       "      <td>32.361500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.024095</td>\n",
       "      <td>32.726357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.056571</td>\n",
       "      <td>32.890881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.083714</td>\n",
       "      <td>31.842548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.139786</td>\n",
       "      <td>31.438810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.209048</td>\n",
       "      <td>33.247619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.560357</td>\n",
       "      <td>31.651643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.453286</td>\n",
       "      <td>31.488714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.389548</td>\n",
       "      <td>31.414310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>80.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.300738</td>\n",
       "      <td>31.309286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.254143</td>\n",
       "      <td>30.970214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.127000</td>\n",
       "      <td>30.853714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.168357</td>\n",
       "      <td>30.927667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.359381</td>\n",
       "      <td>31.036429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.359524</td>\n",
       "      <td>30.926262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.350905</td>\n",
       "      <td>31.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>80.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.463976</td>\n",
       "      <td>31.056381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.745738</td>\n",
       "      <td>31.568929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.861429</td>\n",
       "      <td>31.418024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.578786</td>\n",
       "      <td>31.145452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.007190</td>\n",
       "      <td>31.514881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.803452</td>\n",
       "      <td>31.660881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.046262</td>\n",
       "      <td>31.773905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.672214</td>\n",
       "      <td>29.840167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>90.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.102000</td>\n",
       "      <td>30.104762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.527310</td>\n",
       "      <td>30.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.407690</td>\n",
       "      <td>30.582405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.948524</td>\n",
       "      <td>30.789048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.851429</td>\n",
       "      <td>30.593714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.051881</td>\n",
       "      <td>30.787214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.197143</td>\n",
       "      <td>31.087833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>90.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.262667</td>\n",
       "      <td>30.941214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.246357</td>\n",
       "      <td>31.047500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Watts  Inclination  Flow Rate  Fluid_ratio  T Atmosphere  \\\n",
       "0    40.0          0.0        0.2          0.8     30.026381   \n",
       "1    50.0          0.0        0.2          0.8     30.680929   \n",
       "2    60.0          0.0        0.2          0.8     30.770452   \n",
       "3    70.0          0.0        0.2          0.8     30.741786   \n",
       "4    80.0          0.0        0.2          0.8     30.711814   \n",
       "5    90.0          0.0        0.2          0.8     30.699886   \n",
       "6   100.0          0.0        0.2          0.8     30.651714   \n",
       "7    40.0          0.0        0.3          0.8     29.909881   \n",
       "8    50.0          0.0        0.3          0.8     29.924000   \n",
       "9    60.0          0.0        0.3          0.8     30.027071   \n",
       "10   70.0          0.0        0.3          0.8     30.024095   \n",
       "11   80.0          0.0        0.3          0.8     30.056571   \n",
       "12   90.0          0.0        0.3          0.8     30.083714   \n",
       "13  100.0          0.0        0.3          0.8     30.139786   \n",
       "14   40.0         30.0        0.2          0.8     30.209048   \n",
       "15   50.0         30.0        0.2          0.8     30.560357   \n",
       "16   60.0         30.0        0.2          0.8     30.453286   \n",
       "17   70.0         30.0        0.2          0.8     30.389548   \n",
       "18   80.0         30.0        0.2          0.8     30.300738   \n",
       "19   90.0         30.0        0.2          0.8     30.254143   \n",
       "20  100.0         30.0        0.2          0.8     30.127000   \n",
       "21   40.0         30.0        0.3          0.8     29.168357   \n",
       "22   50.0         30.0        0.3          0.8     29.359381   \n",
       "23   60.0         30.0        0.3          0.8     29.359524   \n",
       "24   70.0         30.0        0.3          0.8     29.350905   \n",
       "25   80.0         30.0        0.3          0.8     29.463976   \n",
       "26   90.0         30.0        0.3          0.8     29.745738   \n",
       "27  100.0         30.0        0.3          0.8     29.861429   \n",
       "28   40.0         45.0        0.2          0.8     29.578786   \n",
       "29   50.0         45.0        0.2          0.8     30.007190   \n",
       "30   60.0         45.0        0.2          0.8     29.803452   \n",
       "31   70.0         45.0        0.2          0.8     30.046262   \n",
       "32   80.0         45.0        0.2          0.8     28.672214   \n",
       "33   90.0         45.0        0.2          0.8     29.102000   \n",
       "34  100.0         45.0        0.2          0.8     29.527310   \n",
       "35   40.0         45.0        0.3          0.8     29.407690   \n",
       "36   50.0         45.0        0.3          0.8     28.948524   \n",
       "37   60.0         45.0        0.3          0.8     28.851429   \n",
       "38   70.0         45.0        0.3          0.8     29.051881   \n",
       "39   80.0         45.0        0.3          0.8     29.197143   \n",
       "40   90.0         45.0        0.3          0.8     29.262667   \n",
       "41  100.0         45.0        0.3          0.8     29.246357   \n",
       "\n",
       "    Water_Inlet_Temperature  \n",
       "0                 31.478524  \n",
       "1                 32.132071  \n",
       "2                 32.219429  \n",
       "3                 32.091071  \n",
       "4                 32.073558  \n",
       "5                 32.050455  \n",
       "6                 31.968500  \n",
       "7                 31.684571  \n",
       "8                 32.025500  \n",
       "9                 32.361500  \n",
       "10                32.726357  \n",
       "11                32.890881  \n",
       "12                31.842548  \n",
       "13                31.438810  \n",
       "14                33.247619  \n",
       "15                31.651643  \n",
       "16                31.488714  \n",
       "17                31.414310  \n",
       "18                31.309286  \n",
       "19                30.970214  \n",
       "20                30.853714  \n",
       "21                30.927667  \n",
       "22                31.036429  \n",
       "23                30.926262  \n",
       "24                31.714286  \n",
       "25                31.056381  \n",
       "26                31.568929  \n",
       "27                31.418024  \n",
       "28                31.145452  \n",
       "29                31.514881  \n",
       "30                31.660881  \n",
       "31                31.773905  \n",
       "32                29.840167  \n",
       "33                30.104762  \n",
       "34                30.331000  \n",
       "35                30.582405  \n",
       "36                30.789048  \n",
       "37                30.593714  \n",
       "38                30.787214  \n",
       "39                31.087833  \n",
       "40                30.941214  \n",
       "41                31.047500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to display training set or X_train\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>32.845049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>34.361976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>34.981143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>35.386738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>35.766884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>36.225409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>36.662762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>32.801143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>33.393048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>34.012762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>34.588524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>35.062119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>34.532333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>34.406405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>34.559571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>33.703524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>33.977476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>34.357738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>34.634524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>34.891190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>35.179548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>31.952619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>32.367143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>32.628476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>33.606429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>33.372714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>34.156643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>34.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>32.667786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>33.491905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>33.894738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>34.556810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>33.250857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>33.706381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>34.428929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>31.628548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>32.095452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>32.291738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>32.771548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>33.322262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>33.546095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>33.939238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Outlet\n",
       "0   32.845049\n",
       "1   34.361976\n",
       "2   34.981143\n",
       "3   35.386738\n",
       "4   35.766884\n",
       "5   36.225409\n",
       "6   36.662762\n",
       "7   32.801143\n",
       "8   33.393048\n",
       "9   34.012762\n",
       "10  34.588524\n",
       "11  35.062119\n",
       "12  34.532333\n",
       "13  34.406405\n",
       "14  34.559571\n",
       "15  33.703524\n",
       "16  33.977476\n",
       "17  34.357738\n",
       "18  34.634524\n",
       "19  34.891190\n",
       "20  35.179548\n",
       "21  31.952619\n",
       "22  32.367143\n",
       "23  32.628476\n",
       "24  33.606429\n",
       "25  33.372714\n",
       "26  34.156643\n",
       "27  34.283333\n",
       "28  32.667786\n",
       "29  33.491905\n",
       "30  33.894738\n",
       "31  34.556810\n",
       "32  33.250857\n",
       "33  33.706381\n",
       "34  34.428929\n",
       "35  31.628548\n",
       "36  32.095452\n",
       "37  32.291738\n",
       "38  32.771548\n",
       "39  33.322262\n",
       "40  33.546095\n",
       "41  33.939238"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To display Y_train\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape[0] = 42\n",
      "X_train.shape[1] = 6\n"
     ]
    }
   ],
   "source": [
    "#TO reshape row and column of X_train\n",
    "import numpy as np\n",
    "X_train = np.reshape(X_train,( X_train.shape[0],X_train.shape[1], 1 ))\n",
    "# To print X_train.shpae[0] and shapr[1] after reshape\n",
    "print(\"X_train.shape[0] = \" + str(X_train.shape[0]))\n",
    "print(\"X_train.shape[1] = \" + str(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 6, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape# display size of X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape# display size of Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sivge\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 6, 8)              16        \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 6, 12)             108       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 73        \n",
      "=================================================================\n",
      "Total params: 197\n",
      "Trainable params: 197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#To Build CNN Model\n",
    "from __future__ import print_function    \n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution1D, MaxPooling1D \n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(8, 1,input_shape=(6, 1)))\n",
    "\n",
    "model.add(Convolution1D(12, 1, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "WARNING:tensorflow:From C:\\Users\\sivge\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 42 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 478.0993 - mae: 21.7038 - val_loss: 297.9912 - val_mae: 17.2035\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 180.0435 - mae: 13.0405 - val_loss: 78.9899 - val_mae: 8.5751\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 39.2188 - mae: 5.2349 - val_loss: 14.4728 - val_mae: 3.0636\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 12.7136 - mae: 2.8894 - val_loss: 11.1864 - val_mae: 2.7793\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.9542 - mae: 2.7285 - val_loss: 10.3035 - val_mae: 2.6428\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.0636 - mae: 2.6021 - val_loss: 9.6756 - val_mae: 2.5636\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.8508 - mae: 2.5827 - val_loss: 9.0512 - val_mae: 2.4715\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.9346 - mae: 2.4560 - val_loss: 8.4435 - val_mae: 2.3964\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.1581 - mae: 2.3591 - val_loss: 7.7532 - val_mae: 2.2971\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.5919 - mae: 2.2728 - val_loss: 7.2180 - val_mae: 2.2157\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.1195 - mae: 2.2072 - val_loss: 6.6283 - val_mae: 2.1211\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.5781 - mae: 2.1564 - val_loss: 6.1142 - val_mae: 2.0486\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.9619 - mae: 2.0146 - val_loss: 5.5536 - val_mae: 1.9454\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.4547 - mae: 1.9411 - val_loss: 5.0367 - val_mae: 1.8649\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9846 - mae: 1.8508 - val_loss: 4.6514 - val_mae: 1.7953\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5382 - mae: 1.7695 - val_loss: 4.2105 - val_mae: 1.7100\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.0705 - mae: 1.6794 - val_loss: 3.8270 - val_mae: 1.6381\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 3.8693 - mae: 1.6440 - val_loss: 3.4641 - val_mae: 1.5617\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 3.3383 - mae: 1.5318 - val_loss: 3.1144 - val_mae: 1.4803\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 3.1101 - mae: 1.4521 - val_loss: 2.8000 - val_mae: 1.4076\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.7326 - mae: 1.3965 - val_loss: 2.5187 - val_mae: 1.3355\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.4459 - mae: 1.3180 - val_loss: 2.2453 - val_mae: 1.2591\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.2512 - mae: 1.2467 - val_loss: 2.0158 - val_mae: 1.1886\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9218 - mae: 1.1668 - val_loss: 1.7953 - val_mae: 1.1362\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7229 - mae: 1.1057 - val_loss: 1.5703 - val_mae: 1.0588\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5346 - mae: 1.0520 - val_loss: 1.4258 - val_mae: 1.0063\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.4241 - mae: 0.9895 - val_loss: 1.2472 - val_mae: 0.9418\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.2160 - mae: 0.9353 - val_loss: 1.1032 - val_mae: 0.8795\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.2074 - mae: 0.9258 - val_loss: 1.0379 - val_mae: 0.8690\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9602 - mae: 0.8279 - val_loss: 0.8555 - val_mae: 0.7726\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8231 - mae: 0.7566 - val_loss: 0.7623 - val_mae: 0.7238\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.7472 - mae: 0.7211 - val_loss: 0.6674 - val_mae: 0.6797\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6730 - mae: 0.6662 - val_loss: 0.5999 - val_mae: 0.6346\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6342 - mae: 0.6609 - val_loss: 0.5306 - val_mae: 0.5910\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5070 - mae: 0.5747 - val_loss: 0.4743 - val_mae: 0.5665\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4704 - mae: 0.5702 - val_loss: 0.4268 - val_mae: 0.5368\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4356 - mae: 0.5221 - val_loss: 0.3868 - val_mae: 0.5089\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3773 - mae: 0.4993 - val_loss: 0.3485 - val_mae: 0.4792\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3470 - mae: 0.4796 - val_loss: 0.3235 - val_mae: 0.4590\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3406 - mae: 0.4744 - val_loss: 0.2968 - val_mae: 0.4412\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3260 - mae: 0.4543 - val_loss: 0.2892 - val_mae: 0.4299\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2978 - mae: 0.4433 - val_loss: 0.2623 - val_mae: 0.4177\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2590 - mae: 0.4174 - val_loss: 0.2482 - val_mae: 0.4056\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2868 - mae: 0.4324 - val_loss: 0.2368 - val_mae: 0.4008\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2852 - mae: 0.4429 - val_loss: 0.2289 - val_mae: 0.3985\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2586 - mae: 0.4124 - val_loss: 0.2232 - val_mae: 0.3955\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2268 - mae: 0.3944 - val_loss: 0.2224 - val_mae: 0.4012\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2358 - mae: 0.4178 - val_loss: 0.2108 - val_mae: 0.3941\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2175 - mae: 0.4022 - val_loss: 0.2071 - val_mae: 0.3964\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2154 - mae: 0.4045 - val_loss: 0.2034 - val_mae: 0.3969\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2251 - mae: 0.4052 - val_loss: 0.2020 - val_mae: 0.3976\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2267 - mae: 0.4106 - val_loss: 0.2063 - val_mae: 0.3949\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2119 - mae: 0.3951 - val_loss: 0.2043 - val_mae: 0.4007\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2136 - mae: 0.4147 - val_loss: 0.1978 - val_mae: 0.3995\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2017 - mae: 0.4038 - val_loss: 0.1973 - val_mae: 0.3983\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2144 - mae: 0.4136 - val_loss: 0.1980 - val_mae: 0.3981\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2049 - mae: 0.4111 - val_loss: 0.1962 - val_mae: 0.4014\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2053 - mae: 0.4013 - val_loss: 0.1955 - val_mae: 0.4017\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2173 - mae: 0.4151 - val_loss: 0.1987 - val_mae: 0.4029\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2054 - mae: 0.4129 - val_loss: 0.1987 - val_mae: 0.3984\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2081 - mae: 0.3952 - val_loss: 0.2258 - val_mae: 0.4068\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2175 - mae: 0.4147 - val_loss: 0.1937 - val_mae: 0.4011\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2059 - mae: 0.4086 - val_loss: 0.2075 - val_mae: 0.4047\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2120 - mae: 0.4235 - val_loss: 0.2006 - val_mae: 0.3979\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2011 - mae: 0.4074 - val_loss: 0.1937 - val_mae: 0.4010\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2049 - mae: 0.4152 - val_loss: 0.1974 - val_mae: 0.4031\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2092 - mae: 0.4145 - val_loss: 0.1931 - val_mae: 0.4009\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2177 - mae: 0.4201 - val_loss: 0.2219 - val_mae: 0.3984\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1975 - mae: 0.3876 - val_loss: 0.2107 - val_mae: 0.4054\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2350 - mae: 0.4236 - val_loss: 0.2051 - val_mae: 0.3968\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2003 - mae: 0.4024 - val_loss: 0.1959 - val_mae: 0.4022\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2090 - mae: 0.4112 - val_loss: 0.2137 - val_mae: 0.3985\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2465 - mae: 0.4204 - val_loss: 0.1943 - val_mae: 0.4025\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2148 - mae: 0.4012 - val_loss: 0.2076 - val_mae: 0.4049\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3027 - mae: 0.4642 - val_loss: 0.2090 - val_mae: 0.3976\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2626 - mae: 0.4373 - val_loss: 0.2433 - val_mae: 0.4005\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2344 - mae: 0.4155 - val_loss: 0.1993 - val_mae: 0.4040\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2095 - mae: 0.4074 - val_loss: 0.1930 - val_mae: 0.4014\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2081 - mae: 0.4124 - val_loss: 0.1980 - val_mae: 0.3974\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2084 - mae: 0.4160 - val_loss: 0.1923 - val_mae: 0.3996\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2163 - mae: 0.4136 - val_loss: 0.2356 - val_mae: 0.4077\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2155 - mae: 0.3965 - val_loss: 0.1994 - val_mae: 0.3966\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2074 - mae: 0.4067 - val_loss: 0.1980 - val_mae: 0.3967\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2136 - mae: 0.3975 - val_loss: 0.2277 - val_mae: 0.4067\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2202 - mae: 0.4155 - val_loss: 0.1959 - val_mae: 0.4027\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2235 - mae: 0.4207 - val_loss: 0.2214 - val_mae: 0.4066\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2376 - mae: 0.4370 - val_loss: 0.1915 - val_mae: 0.4000\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2183 - mae: 0.4166 - val_loss: 0.1998 - val_mae: 0.3964\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2098 - mae: 0.4081 - val_loss: 0.1948 - val_mae: 0.3983\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2203 - mae: 0.4115 - val_loss: 0.1933 - val_mae: 0.4015\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2041 - mae: 0.3950 - val_loss: 0.2322 - val_mae: 0.3975\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2224 - mae: 0.4119 - val_loss: 0.1908 - val_mae: 0.3993\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2080 - mae: 0.4045 - val_loss: 0.1923 - val_mae: 0.4008\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2106 - mae: 0.4095 - val_loss: 0.2186 - val_mae: 0.3964\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2281 - mae: 0.4134 - val_loss: 0.2095 - val_mae: 0.4038\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2085 - mae: 0.4157 - val_loss: 0.1930 - val_mae: 0.3965\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1963 - mae: 0.3933 - val_loss: 0.2018 - val_mae: 0.4021\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2466 - mae: 0.4376 - val_loss: 0.2599 - val_mae: 0.4021\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2157 - mae: 0.4055 - val_loss: 0.1924 - val_mae: 0.3969\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2128 - mae: 0.3824 - val_loss: 0.2493 - val_mae: 0.4134\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2407 - mae: 0.4269 - val_loss: 0.1925 - val_mae: 0.4010\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2241 - mae: 0.4177 - val_loss: 0.2062 - val_mae: 0.3955\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2068 - mae: 0.4130 - val_loss: 0.1911 - val_mae: 0.3973\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2072 - mae: 0.4159 - val_loss: 0.1900 - val_mae: 0.3975\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2101 - mae: 0.4145 - val_loss: 0.1918 - val_mae: 0.3958\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2100 - mae: 0.4048 - val_loss: 0.1963 - val_mae: 0.3949\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1996 - mae: 0.3646 - val_loss: 0.3947 - val_mae: 0.5068\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2864 - mae: 0.4687 - val_loss: 0.1960 - val_mae: 0.3993\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2149 - mae: 0.4156 - val_loss: 0.1969 - val_mae: 0.3940\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2246 - mae: 0.4222 - val_loss: 0.1888 - val_mae: 0.3968\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2070 - mae: 0.4015 - val_loss: 0.1925 - val_mae: 0.3988\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2025 - mae: 0.3817 - val_loss: 0.2079 - val_mae: 0.3927\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2051 - mae: 0.4060 - val_loss: 0.1932 - val_mae: 0.3922\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2083 - mae: 0.4146 - val_loss: 0.1961 - val_mae: 0.3977\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1989 - mae: 0.3599 - val_loss: 0.2885 - val_mae: 0.4060\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2446 - mae: 0.4285 - val_loss: 0.1885 - val_mae: 0.3951\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.4249 - val_loss: 0.2346 - val_mae: 0.3934\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2076 - mae: 0.3993 - val_loss: 0.2751 - val_mae: 0.4264\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2217 - mae: 0.4135 - val_loss: 0.1875 - val_mae: 0.3943\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2111 - mae: 0.4107 - val_loss: 0.2775 - val_mae: 0.4288\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2471 - mae: 0.4103 - val_loss: 0.2006 - val_mae: 0.3910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2270 - mae: 0.4143 - val_loss: 0.2357 - val_mae: 0.3905\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2113 - mae: 0.3852 - val_loss: 0.2235 - val_mae: 0.4001\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2256 - mae: 0.4042 - val_loss: 0.1991 - val_mae: 0.3969\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1960 - mae: 0.3801 - val_loss: 0.2743 - val_mae: 0.4028\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3112 - mae: 0.4245 - val_loss: 0.1956 - val_mae: 0.3881\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3415 - mae: 0.4961 - val_loss: 0.2144 - val_mae: 0.3912\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2450 - mae: 0.3986 - val_loss: 0.1977 - val_mae: 0.3971\n",
      "Epoch 129/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1992 - mae: 0.4002 - val_loss: 0.1877 - val_mae: 0.3924\n",
      "Epoch 130/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1996 - mae: 0.3932 - val_loss: 0.2025 - val_mae: 0.3966\n",
      "Epoch 131/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2555 - mae: 0.4618 - val_loss: 0.2888 - val_mae: 0.4357\n",
      "Epoch 132/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3215 - mae: 0.4683 - val_loss: 0.1866 - val_mae: 0.3902\n",
      "Epoch 133/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2260 - mae: 0.3733 - val_loss: 0.3602 - val_mae: 0.4632\n",
      "Epoch 134/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2242 - mae: 0.3876 - val_loss: 0.2033 - val_mae: 0.3913\n",
      "Epoch 135/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2356 - mae: 0.4227 - val_loss: 0.1992 - val_mae: 0.3843\n",
      "Epoch 136/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2565 - mae: 0.4276 - val_loss: 0.2174 - val_mae: 0.3956\n",
      "Epoch 137/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2171 - mae: 0.3957 - val_loss: 0.3476 - val_mae: 0.4521\n",
      "Epoch 138/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2363 - mae: 0.4190 - val_loss: 0.1883 - val_mae: 0.3880\n",
      "Epoch 139/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2047 - mae: 0.3953 - val_loss: 0.2485 - val_mae: 0.4101\n",
      "Epoch 140/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2242 - mae: 0.4244 - val_loss: 0.1962 - val_mae: 0.3880\n",
      "Epoch 141/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2274 - mae: 0.4205 - val_loss: 0.2083 - val_mae: 0.3960\n",
      "Epoch 142/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2840 - mae: 0.4283 - val_loss: 0.2472 - val_mae: 0.3910\n",
      "Epoch 143/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2456 - mae: 0.4293 - val_loss: 0.1848 - val_mae: 0.3931\n",
      "Epoch 144/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1898 - mae: 0.3926 - val_loss: 0.2060 - val_mae: 0.3894\n",
      "Epoch 145/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2250 - mae: 0.4206 - val_loss: 0.2063 - val_mae: 0.3896\n",
      "Epoch 146/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1958 - mae: 0.4003 - val_loss: 0.1897 - val_mae: 0.3924\n",
      "Epoch 147/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2175 - mae: 0.4067 - val_loss: 0.1835 - val_mae: 0.3904\n",
      "Epoch 148/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2093 - mae: 0.3914 - val_loss: 0.3233 - val_mae: 0.4312\n",
      "Epoch 149/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3789 - mae: 0.4872 - val_loss: 0.4829 - val_mae: 0.5624\n",
      "Epoch 150/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2010 - mae: 0.3795 - val_loss: 0.1912 - val_mae: 0.3948\n",
      "Epoch 151/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1998 - mae: 0.3990 - val_loss: 0.2033 - val_mae: 0.3960\n",
      "Epoch 152/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2173 - mae: 0.4148 - val_loss: 0.2087 - val_mae: 0.3877\n",
      "Epoch 153/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2712 - mae: 0.3943 - val_loss: 0.2833 - val_mae: 0.4074\n",
      "Epoch 154/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2491 - mae: 0.4075 - val_loss: 0.2405 - val_mae: 0.3885\n",
      "Epoch 155/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2230 - mae: 0.4143 - val_loss: 0.1819 - val_mae: 0.3892\n",
      "Epoch 156/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2585 - mae: 0.4561 - val_loss: 0.2179 - val_mae: 0.3864\n",
      "Epoch 157/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2063 - mae: 0.3920 - val_loss: 0.2615 - val_mae: 0.3986\n",
      "Epoch 158/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.4097 - val_loss: 0.1862 - val_mae: 0.3856\n",
      "Epoch 159/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1920 - mae: 0.3857 - val_loss: 0.2558 - val_mae: 0.4188\n",
      "Epoch 160/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2436 - mae: 0.4304 - val_loss: 0.1892 - val_mae: 0.3841\n",
      "Epoch 161/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2243 - mae: 0.4187 - val_loss: 0.1849 - val_mae: 0.3861\n",
      "Epoch 162/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2480 - mae: 0.4331 - val_loss: 0.2868 - val_mae: 0.4050\n",
      "Epoch 163/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2589 - mae: 0.4290 - val_loss: 0.2029 - val_mae: 0.3808\n",
      "Epoch 164/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2175 - mae: 0.4089 - val_loss: 0.1884 - val_mae: 0.3811\n",
      "Epoch 165/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2088 - mae: 0.4041 - val_loss: 0.1798 - val_mae: 0.3861\n",
      "Epoch 166/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2577 - mae: 0.4180 - val_loss: 0.2652 - val_mae: 0.4128\n",
      "Epoch 167/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2091 - mae: 0.3805 - val_loss: 0.3730 - val_mae: 0.5013\n",
      "Epoch 168/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2224 - mae: 0.3953 - val_loss: 0.1813 - val_mae: 0.3823\n",
      "Epoch 169/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1832 - mae: 0.3720 - val_loss: 0.2871 - val_mae: 0.4092\n",
      "Epoch 170/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3174 - mae: 0.4854 - val_loss: 0.5037 - val_mae: 0.5738\n",
      "Epoch 171/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2383 - mae: 0.4152 - val_loss: 0.1803 - val_mae: 0.3822\n",
      "Epoch 172/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2139 - mae: 0.3967 - val_loss: 0.1831 - val_mae: 0.3797\n",
      "Epoch 173/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2187 - mae: 0.4089 - val_loss: 0.2089 - val_mae: 0.3803\n",
      "Epoch 174/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2630 - mae: 0.3786 - val_loss: 0.1835 - val_mae: 0.3788\n",
      "Epoch 175/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2167 - mae: 0.4036 - val_loss: 0.1846 - val_mae: 0.3824\n",
      "Epoch 176/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2103 - mae: 0.4110 - val_loss: 0.2653 - val_mae: 0.3964\n",
      "Epoch 177/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2907 - mae: 0.4526 - val_loss: 0.1904 - val_mae: 0.3811\n",
      "Epoch 178/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2159 - mae: 0.4082 - val_loss: 0.1873 - val_mae: 0.3865\n",
      "Epoch 179/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2214 - mae: 0.4075 - val_loss: 0.2295 - val_mae: 0.4016\n",
      "Epoch 180/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2348 - mae: 0.4234 - val_loss: 0.2847 - val_mae: 0.4065\n",
      "Epoch 181/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2436 - mae: 0.4115 - val_loss: 0.2357 - val_mae: 0.3811\n",
      "Epoch 182/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1916 - mae: 0.3484 - val_loss: 0.1925 - val_mae: 0.3827\n",
      "Epoch 183/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1937 - mae: 0.3828 - val_loss: 0.1828 - val_mae: 0.3758\n",
      "Epoch 184/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1940 - mae: 0.3832 - val_loss: 0.1799 - val_mae: 0.3806\n",
      "Epoch 185/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2280 - mae: 0.3982 - val_loss: 0.1897 - val_mae: 0.3836\n",
      "Epoch 186/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2088 - mae: 0.3947 - val_loss: 0.2376 - val_mae: 0.3799\n",
      "Epoch 187/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2972 - mae: 0.4422 - val_loss: 0.1824 - val_mae: 0.3810\n",
      "Epoch 188/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2163 - mae: 0.4078 - val_loss: 0.2094 - val_mae: 0.3775\n",
      "Epoch 189/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2573 - mae: 0.4316 - val_loss: 0.2101 - val_mae: 0.3881\n",
      "Epoch 190/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2309 - mae: 0.4177 - val_loss: 0.2192 - val_mae: 0.3765\n",
      "Epoch 191/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2589 - mae: 0.4457 - val_loss: 0.1855 - val_mae: 0.3762\n",
      "Epoch 192/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2038 - mae: 0.4002 - val_loss: 0.1762 - val_mae: 0.3766\n",
      "Epoch 193/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2312 - mae: 0.3971 - val_loss: 0.1800 - val_mae: 0.3802\n",
      "Epoch 194/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1820 - mae: 0.3546 - val_loss: 0.3333 - val_mae: 0.4681\n",
      "Epoch 195/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1998 - mae: 0.3626 - val_loss: 0.2041 - val_mae: 0.3796\n",
      "Epoch 196/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2214 - mae: 0.4006 - val_loss: 0.1735 - val_mae: 0.3761\n",
      "Epoch 197/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1853 - mae: 0.3901 - val_loss: 0.1766 - val_mae: 0.3776\n",
      "Epoch 198/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2127 - mae: 0.3976 - val_loss: 0.1796 - val_mae: 0.3779\n",
      "Epoch 199/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2498 - mae: 0.4175 - val_loss: 0.1755 - val_mae: 0.3727\n",
      "Epoch 200/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2134 - mae: 0.3823 - val_loss: 0.1750 - val_mae: 0.3745\n",
      "Epoch 201/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2382 - mae: 0.4079 - val_loss: 0.2049 - val_mae: 0.3830\n",
      "Epoch 202/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3195 - mae: 0.4480 - val_loss: 0.3959 - val_mae: 0.5093\n",
      "Epoch 203/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2676 - mae: 0.4231 - val_loss: 0.1949 - val_mae: 0.3817\n",
      "Epoch 204/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1990 - mae: 0.3876 - val_loss: 0.1825 - val_mae: 0.3730\n",
      "Epoch 205/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1992 - mae: 0.3786 - val_loss: 0.1807 - val_mae: 0.3761\n",
      "Epoch 206/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2813 - mae: 0.4391 - val_loss: 0.3276 - val_mae: 0.4427\n",
      "Epoch 207/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2484 - mae: 0.4109 - val_loss: 0.2650 - val_mae: 0.4120\n",
      "Epoch 208/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2687 - mae: 0.4097 - val_loss: 0.2044 - val_mae: 0.3830\n",
      "Epoch 209/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2163 - mae: 0.3792 - val_loss: 0.2116 - val_mae: 0.3809\n",
      "Epoch 210/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2104 - mae: 0.3980 - val_loss: 0.2006 - val_mae: 0.3698\n",
      "Epoch 211/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2309 - mae: 0.3807 - val_loss: 0.2292 - val_mae: 0.3737\n",
      "Epoch 212/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2414 - mae: 0.4086 - val_loss: 0.1714 - val_mae: 0.3707\n",
      "Epoch 213/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2340 - mae: 0.3944 - val_loss: 0.1692 - val_mae: 0.3693\n",
      "Epoch 214/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2268 - mae: 0.4020 - val_loss: 0.2405 - val_mae: 0.3773\n",
      "Epoch 215/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2555 - mae: 0.4113 - val_loss: 0.2283 - val_mae: 0.3721\n",
      "Epoch 216/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2284 - mae: 0.4115 - val_loss: 0.1978 - val_mae: 0.3768\n",
      "Epoch 217/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2941 - mae: 0.4437 - val_loss: 0.2765 - val_mae: 0.4170\n",
      "Epoch 218/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2134 - mae: 0.4038 - val_loss: 0.2437 - val_mae: 0.3778\n",
      "Epoch 219/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2259 - mae: 0.4125 - val_loss: 0.1760 - val_mae: 0.3685\n",
      "Epoch 220/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2176 - mae: 0.3829 - val_loss: 0.1912 - val_mae: 0.3753\n",
      "Epoch 221/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1938 - mae: 0.3946 - val_loss: 0.2591 - val_mae: 0.3937\n",
      "Epoch 222/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2288 - mae: 0.4039 - val_loss: 0.1700 - val_mae: 0.3680\n",
      "Epoch 223/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2348 - mae: 0.4110 - val_loss: 0.2230 - val_mae: 0.3902\n",
      "Epoch 224/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1954 - mae: 0.3692 - val_loss: 0.1915 - val_mae: 0.3735\n",
      "Epoch 225/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - mae: 0.4105 - val_loss: 0.1700 - val_mae: 0.3616\n",
      "Epoch 226/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2797 - mae: 0.4388 - val_loss: 0.4813 - val_mae: 0.5779\n",
      "Epoch 227/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2979 - mae: 0.4524 - val_loss: 0.2126 - val_mae: 0.3722\n",
      "Epoch 228/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2777 - mae: 0.4070 - val_loss: 0.1795 - val_mae: 0.3628\n",
      "Epoch 229/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2676 - mae: 0.4222 - val_loss: 0.2129 - val_mae: 0.3763\n",
      "Epoch 230/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2152 - mae: 0.4087 - val_loss: 0.1805 - val_mae: 0.3601\n",
      "Epoch 231/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2339 - mae: 0.4012 - val_loss: 0.2618 - val_mae: 0.3935\n",
      "Epoch 232/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2631 - mae: 0.4021 - val_loss: 0.1744 - val_mae: 0.3565\n",
      "Epoch 233/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2466 - mae: 0.4306 - val_loss: 0.2110 - val_mae: 0.3767\n",
      "Epoch 234/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1671 - mae: 0.3299 - val_loss: 0.1702 - val_mae: 0.3574\n",
      "Epoch 235/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2144 - mae: 0.3962 - val_loss: 0.1776 - val_mae: 0.3670\n",
      "Epoch 236/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2943 - mae: 0.4698 - val_loss: 0.2813 - val_mae: 0.4014\n",
      "Epoch 237/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2156 - mae: 0.3735 - val_loss: 0.1762 - val_mae: 0.3569\n",
      "Epoch 238/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2295 - mae: 0.3957 - val_loss: 0.2273 - val_mae: 0.3910\n",
      "Epoch 239/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2319 - mae: 0.3942 - val_loss: 0.3120 - val_mae: 0.4327\n",
      "Epoch 240/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2166 - mae: 0.3574 - val_loss: 0.1681 - val_mae: 0.3542\n",
      "Epoch 241/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2016 - mae: 0.3741 - val_loss: 0.1780 - val_mae: 0.3632\n",
      "Epoch 242/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2278 - mae: 0.3844 - val_loss: 0.1728 - val_mae: 0.3610\n",
      "Epoch 243/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1824 - mae: 0.3658 - val_loss: 0.2116 - val_mae: 0.3743\n",
      "Epoch 244/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1827 - mae: 0.3814 - val_loss: 0.1637 - val_mae: 0.3582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1848 - mae: 0.3669 - val_loss: 0.1705 - val_mae: 0.3599\n",
      "Epoch 246/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1973 - mae: 0.3691 - val_loss: 0.1746 - val_mae: 0.3513\n",
      "Epoch 247/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1785 - mae: 0.3718 - val_loss: 0.1873 - val_mae: 0.3659\n",
      "Epoch 248/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2013 - mae: 0.3912 - val_loss: 0.1987 - val_mae: 0.3696\n",
      "Epoch 249/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1782 - mae: 0.3403 - val_loss: 0.1715 - val_mae: 0.3547\n",
      "Epoch 250/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1793 - mae: 0.3666 - val_loss: 0.1600 - val_mae: 0.3490\n",
      "Epoch 251/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1973 - mae: 0.3670 - val_loss: 0.3013 - val_mae: 0.4197\n",
      "Epoch 252/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2343 - mae: 0.3951 - val_loss: 0.1751 - val_mae: 0.3473\n",
      "Epoch 253/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1745 - mae: 0.3722 - val_loss: 0.1597 - val_mae: 0.3527\n",
      "Epoch 254/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2170 - mae: 0.4016 - val_loss: 0.1771 - val_mae: 0.3487\n",
      "Epoch 255/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1922 - mae: 0.3778 - val_loss: 0.1555 - val_mae: 0.3498\n",
      "Epoch 256/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1787 - mae: 0.3791 - val_loss: 0.1825 - val_mae: 0.3557\n",
      "Epoch 257/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1965 - mae: 0.3738 - val_loss: 0.1540 - val_mae: 0.3510\n",
      "Epoch 258/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2559 - mae: 0.4390 - val_loss: 0.1920 - val_mae: 0.3600\n",
      "Epoch 259/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1835 - mae: 0.3803 - val_loss: 0.1549 - val_mae: 0.3469\n",
      "Epoch 260/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1808 - mae: 0.3428 - val_loss: 0.1548 - val_mae: 0.3453\n",
      "Epoch 261/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1861 - mae: 0.3751 - val_loss: 0.1568 - val_mae: 0.3421\n",
      "Epoch 262/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1735 - mae: 0.3738 - val_loss: 0.1721 - val_mae: 0.3435\n",
      "Epoch 263/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1769 - mae: 0.3621 - val_loss: 0.1651 - val_mae: 0.3426\n",
      "Epoch 264/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1987 - mae: 0.3566 - val_loss: 0.3152 - val_mae: 0.4714\n",
      "Epoch 265/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2243 - mae: 0.3936 - val_loss: 0.1575 - val_mae: 0.3370\n",
      "Epoch 266/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2559 - mae: 0.4017 - val_loss: 0.2415 - val_mae: 0.3738\n",
      "Epoch 267/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1470 - mae: 0.3038 - val_loss: 0.2461 - val_mae: 0.3856\n",
      "Epoch 268/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2323 - mae: 0.3967 - val_loss: 0.1737 - val_mae: 0.3502\n",
      "Epoch 269/300\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1988 - mae: 0.3770 - val_loss: 0.1635 - val_mae: 0.3368\n",
      "Epoch 270/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2172 - mae: 0.3840 - val_loss: 0.2645 - val_mae: 0.3941\n",
      "Epoch 271/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2487 - mae: 0.3773 - val_loss: 0.1534 - val_mae: 0.3373\n",
      "Epoch 272/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2399 - mae: 0.3921 - val_loss: 0.1529 - val_mae: 0.3424\n",
      "Epoch 273/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1950 - mae: 0.3728 - val_loss: 0.2878 - val_mae: 0.4161\n",
      "Epoch 274/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2974 - mae: 0.4376 - val_loss: 0.2555 - val_mae: 0.3904\n",
      "Epoch 275/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1502 - mae: 0.3176 - val_loss: 0.1555 - val_mae: 0.3360\n",
      "Epoch 276/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1716 - mae: 0.3690 - val_loss: 0.1561 - val_mae: 0.3417\n",
      "Epoch 277/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1748 - mae: 0.3679 - val_loss: 0.1959 - val_mae: 0.3605\n",
      "Epoch 278/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1772 - mae: 0.3521 - val_loss: 0.1552 - val_mae: 0.3331\n",
      "Epoch 279/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2301 - mae: 0.3732 - val_loss: 0.2375 - val_mae: 0.3939\n",
      "Epoch 280/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2358 - mae: 0.3926 - val_loss: 0.2504 - val_mae: 0.4020\n",
      "Epoch 281/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2529 - mae: 0.4391 - val_loss: 0.1872 - val_mae: 0.3444\n",
      "Epoch 282/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1622 - mae: 0.3054 - val_loss: 0.1594 - val_mae: 0.3327\n",
      "Epoch 283/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1866 - mae: 0.3513 - val_loss: 0.1440 - val_mae: 0.3270\n",
      "Epoch 284/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1647 - mae: 0.3563 - val_loss: 0.1585 - val_mae: 0.3297\n",
      "Epoch 285/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2055 - mae: 0.3814 - val_loss: 0.1732 - val_mae: 0.3476\n",
      "Epoch 286/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1790 - mae: 0.3625 - val_loss: 0.1444 - val_mae: 0.3304\n",
      "Epoch 287/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1787 - mae: 0.3481 - val_loss: 0.2267 - val_mae: 0.3914\n",
      "Epoch 288/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2380 - mae: 0.3811 - val_loss: 0.1398 - val_mae: 0.3252\n",
      "Epoch 289/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2585 - mae: 0.4002 - val_loss: 0.2881 - val_mae: 0.4252\n",
      "Epoch 290/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2006 - mae: 0.3808 - val_loss: 0.2602 - val_mae: 0.4020\n",
      "Epoch 291/300\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2376 - mae: 0.3830 - val_loss: 0.1566 - val_mae: 0.3323\n",
      "Epoch 292/300\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2000 - mae: 0.3815 - val_loss: 0.1866 - val_mae: 0.3523\n",
      "Epoch 293/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1503 - mae: 0.3051 - val_loss: 0.1379 - val_mae: 0.3209\n",
      "Epoch 294/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1703 - mae: 0.3523 - val_loss: 0.1401 - val_mae: 0.3236\n",
      "Epoch 295/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1798 - mae: 0.3602 - val_loss: 0.1919 - val_mae: 0.3408\n",
      "Epoch 296/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1926 - mae: 0.3621 - val_loss: 0.1562 - val_mae: 0.3192\n",
      "Epoch 297/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1967 - mae: 0.3682 - val_loss: 0.1693 - val_mae: 0.3403\n",
      "Epoch 298/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1754 - mae: 0.3656 - val_loss: 0.1329 - val_mae: 0.3186\n",
      "Epoch 299/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1751 - mae: 0.3357 - val_loss: 0.1330 - val_mae: 0.3144\n",
      "Epoch 300/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1757 - mae: 0.3632 - val_loss: 0.1502 - val_mae: 0.3149\n"
     ]
    }
   ],
   "source": [
    "#To fit model using X_train and Y_Train\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mse\", optimizer=opt,  metrics=['mae'])\n",
    "print(\"[INFO] training model...\")\n",
    "model.fit(X_train, y_train, validation_data=(X_train, y_train),\n",
    "    epochs=300, batch_size=2)\n",
    "model.save('freezemodel300relu.h5')#to save or freeze model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO load model\n",
    "from keras.models import load_model\n",
    "model=load_model('freezemodel300relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape[0] = 1\n",
      "X_test.shape[1] = 6\n"
     ]
    }
   ],
   "source": [
    "# For testing load X_test from folder\n",
    "testing_set = pd.read_csv('C:/Users/sivge/Desktop/Major Project/Main data 80,20/final test.csv', header=None, names=['Watts', 'Inclination', 'Flow_Rate', 'Fluid_ratio','T_atmosphere','water_Inlet_Temp'])\n",
    "X_test = testing_set.iloc[:, :].values\n",
    "print(\"X_test.shape[0] = \" + str(X_test.shape[0]))\n",
    "print(\"X_test.shape[1] = \" + str(X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Watts</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>Flow_Rate</th>\n",
       "      <th>Fluid_ratio</th>\n",
       "      <th>T_atmosphere</th>\n",
       "      <th>water_Inlet_Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.65171</td>\n",
       "      <td>31.9685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Watts  Inclination  Flow_Rate  Fluid_ratio  T_atmosphere  water_Inlet_Temp\n",
       "0  100.0          0.0        0.2          0.8      30.65171           31.9685"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set#to display testing_set or X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape[0] = 1\n",
      "X_test.shape[1] = 6\n"
     ]
    }
   ],
   "source": [
    "#to reshape X_test\n",
    "import numpy as np\n",
    "X_test = np.reshape(X_test,( X_test.shape[0],X_test.shape[1], 1 ))\n",
    "#TO print X_test.shape[0] and X_test.shape[1]\n",
    "print(\"X_test.shape[0] = \" + str(X_test.shape[0]))\n",
    "print(\"X_test.shape[1] = \" + str(X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35.71108]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model using trained model\n",
    "from sklearn.metrics import classification_report\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO write predicted outlet\n",
    "import csv\n",
    "with open('finaloutput.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Watts', 'Inclination', 'Flow Rate', 'T Atmosphere', 'Condenser outlet temperature prediction'])\n",
    "    writer.writerow(['45', '0', '0.2', '31.112', Y_pred])\n",
    "    writer.writerow(['55', '0', '0.2', '30.514', Y_pred])\n",
    "    writer.writerow(['65', '0', '0.2', '33.126', Y_pred])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "x = testing_set\n",
    "y = Y_pred\n",
    "fig=plt.figure()\n",
    "plt.plot(x.Watts, y,\"-o\")\n",
    "plt.plot(x.Watts, x.water_Inlet_Temp,\"-x\")\n",
    "plt.title('comparision',fontsize = 20 )\n",
    "plt.xlabel('Heat input,W',fontsize=16)\n",
    "plt.ylabel('Temperature,$\\degree$C',fontsize=16)\n",
    "plt.legend(['Outlet Temp','Inlet Temp'])\n",
    "plt.show()\n",
    "fig.savefig('line plot.jpg',bbox_inches='tight',dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Watts</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>Flow_Rate</th>\n",
       "      <th>Fluid_ratio</th>\n",
       "      <th>T_atmosphere</th>\n",
       "      <th>water_Inlet_Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.407690</td>\n",
       "      <td>30.582405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.948524</td>\n",
       "      <td>30.789048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.851429</td>\n",
       "      <td>30.593714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.051881</td>\n",
       "      <td>30.787214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.197143</td>\n",
       "      <td>31.087833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.262667</td>\n",
       "      <td>30.941214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.246357</td>\n",
       "      <td>31.047500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Watts  Inclination  Flow_Rate  Fluid_ratio  T_atmosphere  water_Inlet_Temp\n",
       "0   40.0         45.0        0.3          0.8     29.407690         30.582405\n",
       "1   50.0         45.0        0.3          0.8     28.948524         30.789048\n",
       "2   60.0         45.0        0.3          0.8     28.851429         30.593714\n",
       "3   70.0         45.0        0.3          0.8     29.051881         30.787214\n",
       "4   80.0         45.0        0.3          0.8     29.197143         31.087833\n",
       "5   90.0         45.0        0.3          0.8     29.262667         30.941214\n",
       "6  100.0         45.0        0.3          0.8     29.246357         31.047500"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.insert(6,\"outlet_temperature\",y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Watts</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>Flow_Rate</th>\n",
       "      <th>Fluid_ratio</th>\n",
       "      <th>T_atmosphere</th>\n",
       "      <th>water_Inlet_Temp</th>\n",
       "      <th>outlet_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.407690</td>\n",
       "      <td>30.582405</td>\n",
       "      <td>32.006638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.948524</td>\n",
       "      <td>30.789048</td>\n",
       "      <td>32.393566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.851429</td>\n",
       "      <td>30.593714</td>\n",
       "      <td>32.602112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.051881</td>\n",
       "      <td>30.787214</td>\n",
       "      <td>33.151829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.197143</td>\n",
       "      <td>31.087833</td>\n",
       "      <td>33.759842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.262667</td>\n",
       "      <td>30.941214</td>\n",
       "      <td>34.043755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.246357</td>\n",
       "      <td>31.047500</td>\n",
       "      <td>34.477898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Watts  Inclination  Flow_Rate  Fluid_ratio  T_atmosphere  water_Inlet_Temp  \\\n",
       "0   40.0         45.0        0.3          0.8     29.407690         30.582405   \n",
       "1   50.0         45.0        0.3          0.8     28.948524         30.789048   \n",
       "2   60.0         45.0        0.3          0.8     28.851429         30.593714   \n",
       "3   70.0         45.0        0.3          0.8     29.051881         30.787214   \n",
       "4   80.0         45.0        0.3          0.8     29.197143         31.087833   \n",
       "5   90.0         45.0        0.3          0.8     29.262667         30.941214   \n",
       "6  100.0         45.0        0.3          0.8     29.246357         31.047500   \n",
       "\n",
       "   outlet_temperature  \n",
       "0           32.006638  \n",
       "1           32.393566  \n",
       "2           32.602112  \n",
       "3           33.151829  \n",
       "4           33.759842  \n",
       "5           34.043755  \n",
       "6           34.477898  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.to_csv('output.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
